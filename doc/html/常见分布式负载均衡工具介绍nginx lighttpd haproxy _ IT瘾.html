<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><link type="text/css" rel="stylesheet" href="/assets/246b4b9a7dae7857/tapestry/default.css"></link><title>常见分布式负载均衡工具介绍nginx lighttpd haproxy | IT瘾</title><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"></meta><meta content="width=device-width, initial-scale=1.0" name="viewport"></meta><link href="/assets/246b4b9a7dae7857/ctx/assets/general.css" type="text/css" rel="stylesheet"></link><link href="/feed.jsp" title="RSS" type="application/rss+xml" rel="alternate"></link><meta content="常见分布式负载均衡工具介绍nginx lighttpd haproxy,, IT社区推荐资讯 " name="description"></meta><meta content=",负载 工具 nginx " name="keywords"></meta><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-27143924-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script><script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?78efaa073c913f69a4024167a777cdfd";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><meta content="Apache Tapestry Framework (version 5.2.6)" name="generator"></meta></head><body><div id="container"><div id="header"><div class="head"><div class="sitename"><a shape="rect" href="http://itindex.net/">IT瘾</a></div><div>IT社区推荐资讯</div></div><div id="nav"><ul><li><a shape="rect" href="/">首页</a></li><li><a shape="rect" href="/relian/">热链</a></li></ul></div></div><div id="pagebody"><div id="mainbody"><div id="postbody"><h1>常见分布式负载均衡工具介绍nginx lighttpd haproxy</h1><div class="itemOrigin" title="http://www.iteye.com/rss/blogs/category/internet">
标签：
<strong>
负载
</strong><strong>
工具
</strong><strong>
nginx
</strong>
| 发表时间：2014-08-07 02:35 | 作者：沙漠绿树 </div><div class="itemOrigin" title="http://hualong.iteye.com/blog/2101225"><!-- Baidu Button BEGIN --><div style="float:right;" class="bdshare_t bds_tools get-codes-bdshare" id="bdshare"><span class="bds_more">分享到：</span><a shape="rect" class="bds_qzone"></a><a shape="rect" class="bds_tsina"></a><a shape="rect" class="bds_tqq"></a><a shape="rect" class="bds_renren"></a><a shape="rect" class="bds_t163"></a></div>
出处：http://www.iteye.com</div><div><div class="cbody"><!--
				<div style="float:left;padding-right:5px">

				</div>
				-->
          
           <div>
  <p>       在架构系统的时候，通常会涉及到分布式，而处分布式里面最前端的是负载均衡器(当然还有cdn)。在网上搜寻一份，对目前常见的负载均衡器做一些介绍和常见组合，不涉及具体配置。</p>
  <p> </p>
  <p>第一种是常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器，它的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；</p>
  <p>第二种是类似于LVS/HAProxy、Nginx的基于Linux的开源免费的负载均衡软件策略,这些都是通过软件级别来实现，所以费用非常低廉，所以我个也比较推荐大家采用第二种方案来实施自己网站的负载均衡需求。除了这些还有：Lighttpd、Apache-mod_proxy、Squid、Socks、TIS FWTK、Delegate。</p>
  <p> </p>
  <p>LVS的特点是：</p>
  <p>1.抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的；   <br />2.配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率；   <br />3.工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived；   <br />4.无流量，保证了均衡器IO的性能不会收到大流量的影响；   <br />5.应用范围比较广，可以对所有应用做负载均衡；   <br />6.软件本身不支持正则处理，不能做动静分离，这个就比较遗憾了；其实现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。如果是网站应用比较庞大的话，实施LVS/DR+Keepalived起来就比较复杂了，特别后面有Windows Server应用的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。</p>
  <p> </p>
  <p>Nginx的特点是：</p>
  <p>1.工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是许多朋友喜欢它的原因之一；   <br />2.Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势所在；   <br />3.Nginx安装和配置比较简单，测试起来比较方便；   <br />4.也可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量；   <br />5.Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；   <br />6.Nginx仅能支持http和Email，这样就在适用范围上面小很多，这个它的弱势；   <br />7.Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP现在也是非常流行的web架构，大有和以前最流行的LAMP架构分庭抗争之势，在高流量的环境中也有很好的效果。   <br />8.Nginx现在作为Web反向加速缓存越来越成熟了，很多朋友都已在生产环境下投入生产了，而且反映效果不错，速度比传统的Squid服务器更快，有兴趣的朋友可以考虑用其作为反向代理加速器。</p>
  <p>HAProxy的特点是：</p>
  <p>1.HAProxy是支持虚拟主机的。   <br />2.能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作。   <br />3.支持url检测后端的服务器出问题的检测会有很好的帮助。   <br />4.它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。   <br />5.HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS，所以我向大家推荐LVS+Keepalived。</p>
  <p>6.HAProxy的算法现在也越来越多了，具体有如下8种：   <br />① roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；   <br />② static-rr，表示根据权重，建议关注；   <br />③ leastconn，表示最少连接者先处理，建议关注；   <br />④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；   <br />⑤ ri，表示根据请求的URI；   <br />⑥ rl_param，表示根据请求的URl参数&apos;balance url_param&apos; requires an URL parameter name；   <br />⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；   <br />⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。   <br /> </p>
  <p> </p>
  <p>Nginx和LVS作对比的结果</p>
  <p>1、Nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下LVS并不具备这样的功能，所 以 Nginx单凭这点可利用的场合就远多于LVS了；但Nginx有用的这些功能使其可调整度要高于LVS，所以经常要去触碰触碰，由LVS的第2条优点 看，触碰多了，人为出问题的几率也就会大。   <br />2、Nginx对网络的依赖较小，理论上只要ping得通，网页访问正常，Nginx就能连得通，Nginx同时还能区分内外网，如果是同时拥有内外网的 节点，就相当于单机拥有了备份线路；LVS就比较依赖于网络环境，目前来看服务器在同一网段内并且LVS使用direct方式分流，效果较能得到保证。另 外注意，LVS需要向托管商至少申请多一个ip来做Visual IP，貌似是不能用本身的IP来做VIP的。要做好LVS管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个HTTP那么简单了。站长教学网 eduyo.com   <br />3、Nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。LVS的安装和配置、测试就要花比较长的时间了，因为同上所述，LVS对网络依赖比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦得多。   <br />4、Nginx也同样能承受很高负载且稳定，但负载度和稳定度差LVS还有几个等级：Nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的；Nginx没有现成的双机热备方案，所以跑在单机上还是风险较大，单机上的事情全都很难说。   <br />5、Nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前LVS中 ldirectd也能支持针对服务器内部的情况来监控，但LVS的原理使其不能重发请求。重发请求这点，譬如用户正在上传一个文件，而处理该上传的节点刚 好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能 会因此而恼火。   <br />6、Nginx对请求的异步处理可以帮助节点服务器减轻负载，假如使用apache直接对外服务，那么出现很多的窄带链接时apache服务器将会占用大 量内存而不能释放，使用多一个Nginx做apache代理的话，这些窄带链接会被Nginx挡住，apache上就不会堆积过多的请求，这样就减少了相 当多的内存占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对apache还是有很大帮助的。LVS没有这些功能，也就无法能 比较。   <br />7、Nginx能支持http和email（email的功能估计比较少人用），LVS所支持的应用在这点上会比Nginx更多。在使用上，一般最前端所 采取的策略应是LVS，也就是DNS的指向应为LVS均衡器，LVS的优点令它非常适合做这个任务。重要的ip地址，最好交由LVS托管，比如数据库的 ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而至。所以将这些重要ip交给 LVS托管是最为稳妥的，这样做的唯一缺点是需要的VIP数量会比较多。Nginx可作为LVS节点机器使用，一是可以利用Nginx的功能，二是可以利 用Nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比Nginx弱不少了，性能上也有所逊色于Nginx。Nginx也 可作为中层代理使用，这一层面Nginx基本上无对手，唯一可以撼动Nginx的就只有lighttpd了，不过lighttpd目前还没有能做到 Nginx完全的功能，配置也不那么清晰易读。另外，中层代理的IP也是重要的，所以中层代理也拥有一个VIP和LVS是最完美的方案了。具体的应用还得 具体分析，如果是比较小的网站（日PV&lt;1000万），用Nginx就完全可以了，如果机器也不少，可以用DNS轮询，LVS所耗费的机器还是比较 多的；大型网站或者重要的服务，机器不发愁的时候，要多多考虑利用LVS   <br /> </p>
  <p> </p>
  <p>反向代理从传输上分可以分为2种：</p>
  <p>1：同步模式(apache-mod_proxy和squid)</p>
  <p>2：异步模式(lighttpd 和 nginx)</p>
  <p> </p>
  <p>在nginx的文档说明中，提到了异步传输模式并提到它可以减少后端连接数和压力，这是为何？</p>
  <p>下面就来讲解下传统的代理（apache/squid）的同步传输和lighttpd,nginx的异步传输的差异。</p>
  <p>   <img alt="" src="http://rk.educity.cn/netgh/images/2009628642.gif"></img></p>
  <p> </p>
  <p> </p>
  <p>同步传输：浏览器发起请求，而后请求会立刻被转到后台，于是在浏览器和后台之间就建立了一个通道。在请求发起直到请求完成，这条通道都是一直存在的。</p>
  <p>   <br />异步传输：浏览器发起请求，请求不会立刻转到后台，而是将请求数据（header）先收到nginx上，然后nginx再把这个请求发到后端，后端处理完之后把数据返回到nginx上，nginx将数据流发到浏览器，这点和lighttpd有点不同，lighttpd是将后端数据完全接收后才发送到浏览器。</p>
  <p> </p>
  <p>Squid作为网页服务器的前置cache服务器，可以代理用户向web服务器请求数据并进行缓存，也可以用在局域网中，使局域网用户通过代理上网。Squid与Linux下其它的代理软件如Apache、Socks、TIS FWTK和delegate相比，下载安装简单，配置简单灵活，支持缓存和多种协议。用ipchains+Squid的解决方案，就可以获得通过缓存高性能的同时能够无缝的访问Internet。</p>
  <p> </p>
  <p>小结：apache和squid的反向会增加后端web的负担，因为每个用户请求都会在proxy上与后端server建立的长久链接，知道数据取完前，连接都不会消失。因为wan速度与lan速度的不同，虽然lan之间的速度是极度快的，但是用户的wan连接决定了这个时间长。而lighttpd和nginx的异步模式，是不管你用户要求的数据有多大，都是先收下来，再与后端联系，这是非常迅速的速度，所以proxy与后端连接时间也会很短，几十M的东西也是几秒内。后端不需要维护这么多连接。而lighttpd也和nginx不同的异步，lighttpd是先收完再转向客户浏览器，而nginx是边收数据边转向用户浏览器。</p>
  <p> </p>
  <p>   <strong>那么这到底有什么好处呢？</strong></p>
  <p>1. 假设用户执行一个上传文件操作，因为用户网速又比较慢，因此需要花半个小时才能把文件传到服务器。squid的同步代理在用户开始上传后就和后台建立了连接，半小时后文件上传结束，由此可见，后台服务器连接保持了半个小时；而nginx异步代理就是先将此文件收到nginx上，因此仅仅是nginx和用户保持了半小时连接，后台服务器在这半小时内没有为这个请求开启连接，半小时后用户上传结束，nginx才将上传内容发到后台，nginx和后台之间的带宽是很充裕的，所以只花了一秒钟就将请求发送到了后台，由此可见，后台服务器连接保持了一秒。同步传输花了后台服务器半个小时，异步传输只花一秒，可见优化程度很大。</p>
  <p>2. 在上面这个例子中，假如后台服务器因为种种原因重启了，上传文件就自然中断了，这对用户来说是非常恼火的一件事情，想必各位也有上传文件传到一半被中断的经历。用nginx代理之后，后台服务器的重启对用户上传的影响减少到了极点，而nginx是非常稳定的并不需要常去重启它，即使需要重启，利用kill -HUP就可以做到不间断重启nginx。</p>
  <p>3. 异步传输可以令负载均衡器更有保障，为什么这么说呢？在其它的均衡器（lvs/haproxy/apache等）里，每个请求都是只有一次机会的，假如用户发起一个请求，结果该请求分到的后台服务器刚好挂掉了，那么这个请求就失败了；而nginx因为是异步的，所以这个请求可以重新发往下一个后台，下一个后台返回了正常的数据，于是这个请求就能成功了。还是用用户上传文件这个例子，假如不但用了nginx代理，而且用了负载均衡，nginx把上传文件发往其中一台后台，但这台服务器突然重启了，nginx收到错误后，会将这个上传文件发到另一台后台，于是用户就不用再花半小时上传一遍。</p>
  <p>4. 假如用户上传一个10GB大小的文件，而后台服务器没有考虑到这个情况，那么后台服务器岂不要崩溃了。用nginx就可以把这些东西都拦在nginx上，通过nginx的上传文件大小限制功能来限制，另外nginx性能非常有保障，就放心的让互联网上那些另类的用户和nginx对抗去吧。</p>
  <p>用异步传输会造成问题：</p>
  <p>后台服务器有提供上传进度的功能的话，用了nginx代理就无法取得进度，这个需要使用nginx的一个第三方模块来实现。</p>
  <p> </p>
  <p>针对高可用（HA）通常做是主备或者集群，也是分布式集群的中的很重要一环，直接避免单点故障。目前使用较多的HA软件有：Keepalived、Heartbeat、 Piranha、Pacemaker；</p>
  <p> </p>
  <p>Keepalived和Heartbeat对比：</p>
  <p> </p>
  <p>Keepalived使用的vrrp协议方式，虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)。Heartbeat是基于主机或网络的服务的高可用方式；   <br />keepalived的目的是模拟路由器的双机。heartbeat的目的是用户service的双机；   <br />lvs的高可用建议用keepavlived。业务的高可用用heartbeat</p>
  <p> </p>
  <p>Piranha 提供了一套解决方案，包括对服务状态的监控、业务服务器的监控和负载服务器本身热备。</p>
  <p> </p>
  <p>Pacemaker 是一个集群资源管理器。它利用你喜欢的集群基础构件（OpenAIS 或heartbeat）提供的消息和成员管理能力来探测并从节点或资源级别的故障中恢复，以实现群集服务（亦称资源）的最大可用性。   <br />它可以做几乎任何规模的集群，并带有一个强大的依赖模式，让管理员能够准确地表达的群集资源之间的关系（包括顺序和位置）。几乎任何可以编写的脚本，都可以作为管理起搏器集群的一部分。尤为重要的是Pacemaker不是一个heartbeat的工具，可能有人存在这样的误解。Pacemaker是一个延续CRM（亦称V2资源管理器）的项目。最初开发的项目是heartbeat，已经成为该项目的子项目。</p>
  <p> </p>
</div>
          
           <br /> <br />
          
             <a href="http://hualong.iteye.com/blog/2101225#comments">已有   <strong>0</strong> 人发表留言，猛击-&gt;&gt;  <strong>这里</strong>&lt;&lt;-参与讨论</a>
          
           <br /> <br /> <br />
ITeye推荐
 <br />
 <ul>  <li>   <a href="http://www.iteye.com/clicks/433" target="_blank">—软件人才免语言低担保 赴美带薪读研！— </a></li></ul>
 <br /> <br /> <br />
          
        </div></div></div><div class="relate"><h3>相关 [负载 工具 nginx] 推荐：</h3><div class="post"><h2><a title="常见分布式负载均衡工具介绍nginx lighttpd haproxy" href="/detail/50637-%E8%B4%9F%E8%BD%BD-%E5%B7%A5%E5%85%B7-nginx">常见分布式负载均衡工具介绍nginx lighttpd haproxy</a></h2>
-  - 互联网 - ITeye博客
<div>       在架构系统的时候，通常会涉及到分布式，而处分布式里面最前端的是负载均衡器(当然还有cdn). 在网上搜寻一份，对目前常见的负载均衡器做一些介绍和常见组合，不涉及具体配置. 第一种是常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器，它的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；. 第二种是类似于LVS/HAProxy、Nginx的基于Linux的开源免费的负载均衡软件策略,这些都是通过软件级别来实现，所以费用非常低廉，所以我个也比较推荐大家采用第二种方案来实施自己网站的负载均衡需求. </div></div><div class="post"><h2><a title="解析nginx负载均衡" href="/detail/38901-%E8%A7%A3%E6%9E%90-nginx-%E8%B4%9F%E8%BD%BD">解析nginx负载均衡</a></h2>
-  - 搜索研发部官方博客
<div>摘要：对于一个大型网站来说，负载均衡是永恒的话题. 随着硬件技术的迅猛发展，越来越多的负载均衡硬件设备涌现出来，如F5 BIG-IP、Citrix NetScaler、Radware等等，虽然可以解决问题，但其高昂的价格却往往令人望而却步，因此负载均衡软件仍然是大部分公司的不二之选. nginx作为webserver的后起之秀，其优秀的反向代理功能和灵活的负载均衡策略受到了业界广泛的关注. 本文将以工业生产为背景，从设计实现和具体应用等方面详细介绍nginx负载均衡策略. 关键字：nginx 负载均衡 反向代理. 随着互联网信息的爆炸性增长，负载均衡（load balance）已经不再是一个很陌生的话题，顾名思义，负载均衡即是将负载分摊到不同的服务单元，既保证服务的可用性，又保证响应足够快，给用户很好的体验. </div></div><div class="post"><h2><a title="nginx负载均衡配置" href="/detail/39452-nginx-%E8%B4%9F%E8%BD%BD">nginx负载均衡配置</a></h2>
-  - 开心平淡对待每一天。热爱生活
<div>  使用负载均衡的话,可以修改配置http节点如下：. #设定http服务器，利用它的反向代理功能提供负载均衡支持. #设定mime类型,类型由mime.type文件定义. #省略上文有的一些配置节点. #设定负载均衡的服务器列表. #weigth参数表示权值，权值越高被分配到的几率越大. server 192.168.8.1x:3128 weight=5;#本机上的Squid开启3128端口. #weigth参数表示权值，权值越高被分配到的几率越大. #第一个虚拟服务器. #侦听192.168.8.x的80端口. #对aspx后缀的进行负载均衡请求. root   /root;      #定义服务器的默认网站根目录位置. </div></div><div class="post"><h2><a title="Nginx负载均衡概览" href="/detail/50995-nginx-%E8%B4%9F%E8%BD%BD">Nginx负载均衡概览</a></h2>
-  - 行业应用 - ITeye博客
<div>Nginx做为一个强大的Web服务器软件，具有高性能、高并发性和低内存占用的特点. 此外，其也能够提供强大的反向代理功能. 俄罗斯大约有超过20%的虚拟主机采用Nginx作为反向代理服务器,在国内也有腾讯、新浪、网易等多家网站在使用Nginx作为反向代理服务器. 据Netcraft统计，世界上最繁忙的网站中有11.48%使用Nginx作为其服务器或者代理服务器. 基于反向代理的功能，Nginx作为负载均衡主要有以下几点理由：. nginx在启动后，会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程. master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程. </div></div><div class="post"><h2><a title="使用Nginx做mssql只读库负载均衡" href="/detail/39938-nginx-mssql-%E8%B4%9F%E8%BD%BD">使用Nginx做mssql只读库负载均衡</a></h2>
-  - 开心平淡对待每一天。热爱生活
<div> 系统：CentOS 5.5 X86_64. 软件：nginx-1.2.1. 默认nginx不支持tcp的负载均衡，需要打补丁，(连接方式：从客户端收到一个连接，将从本地新建一个连接发起到后端服务器)，具体配置如下：. 源码主页：  https://github.com/yaoweibin/nginx_tcp_proxy_module. 修改nginx.conf配置文件. </div></div><div class="post"><h2><a title="Nginx+keepalived做双机热备加tomcat负载均衡" href="/detail/41849-nginx-keepalived-tomcat">Nginx+keepalived做双机热备加tomcat负载均衡</a></h2>
-  - 开心平淡对待每一天。热爱生活
<div>   Nginx+keepalived做双机热备加tomcat负载均衡. 一.Nginx配置. 1.安装Nginx所需pcre库. 2.安装Nginx. ./configure: error: SSL modules require the OpenSSL library.Centos需要安装openssl-devel
Ubuntu则需要安装:sudo apt-get install libssl-dev. 3.修改配置文件为以下内容：. vim /etc/sysctl.conf在最后添加. 6.切割Nginx日志脚本. 把该脚本加到crontab每天00点执行. 注：备机的Nginx和以上安装步骤一样. </div></div><div class="post"><h2><a title="centos下搭建nginx+tomcat实现集群负载与session复制" href="/detail/43471-centos-nginx-tomcat">centos下搭建nginx+tomcat实现集群负载与session复制</a></h2>
-  - CSDN博客系统运维推荐文章
<div>系统均选用最小化安装的centos 5.7. 客户端通过访问nginx做的负载均衡层去访问后端的web运行层（tomcat），如下图：. 另外，关于session复制原理，简单来说如下图：. 负载层：192.168.254.200. 安装：pcre、nginx、nginx-upstream-jvm-route-0.1. 后端tomcat运行层：192.168.254.221、192.168.254.222. 安装：tomcat、jdk. 2.1 负载均衡层安装部署说明. 2.1.2 创建nginx运行帐号. 2.1.3 Pcre安装. 解压pcre安装包：tar xvf pcre-8.13.tar.gz . </div></div><div class="post"><h2><a title="Nginx+keepalived实现负载均衡和高可用性 in ubuntu" href="/detail/45062-nginx-keepalived-%E8%B4%9F%E8%BD%BD">Nginx+keepalived实现负载均衡和高可用性 in ubuntu</a></h2>
-  - ITeye博客
<div>使用Nginx已经有很长一段时间，但是最近才去实践利用Nginx做负载均衡和高可用性. 大致思路：根据keepalived的特性，通过一个虚拟ip来实现主从服务器的切换，如果一台服务器宕机，可以自动切换到另一台备份服务器，从而不影响用户的访问. 以下是我的安装配置步骤，请大家参考指正. 准备两台ubuntu虚拟主机服务器，对应的IP分别是 192.168.1.100   192.168.1.200. 两台主机的ip一定要在相同的网段. 然后查看ifconfig,不难发现与之前的ifconfig 的不同. 也可以通过ip a查看，对应的网卡eth0有两个ipaddress. 两台虚拟主机要使用相同的虚拟IP: 192.168.1.150. </div></div><div class="post"><h2><a title="实现基于nginx的tomcat负载均衡和集群配置" href="/detail/52307-nginx-tomcat-%E8%B4%9F%E8%BD%BD">实现基于nginx的tomcat负载均衡和集群配置</a></h2>
-  - 互联网 - ITeye博客
<div>今天看到&quot;基于apache的tomcat负载均衡和集群配置 &quot;这篇文章成为javaEye热点. 略看了一下，感觉太复杂，要配置的东西太多，因此在这里写出一种更简洁的方法. 要集群tomcat主要是解决SESSION共享的问题，因此我利用memcached来保存session，多台TOMCAT服务器即可共享SESSION了. 你可以自己写tomcat的扩展来保存SESSION到memcached. 这里推荐使用memcached-session-manager这个开源项目（http://code.google.com/p/memcached-session-manager/ ），下面简称msm. </div></div><div class="post"><h2><a title="nginx做负载均衡器以及proxy缓存配置" href="/detail/53587-nginx-%E8%B4%9F%E8%BD%BD-%E5%9D%87%E8%A1%A1%E5%99%A8">nginx做负载均衡器以及proxy缓存配置</a></h2>
-  - SegmentFault 最新的文章
<div>关于nginx的安装和基本配置请参考  nginx，本文在原基础上完成以下几个功能：. 结合proxy和upstream模块实现nginx负载均衡. 结合   nginx_upstream_check_module模块实现后端服务器的健康检查. 使用   nginx-sticky-module扩展模块实现Cookie会话黏贴（session-sticky效果）. 使用proxy模块实现静态文件缓存. 使用   ngx_cache_purge实现更强大的缓存清除功能. 更多内容见我的博客   http://seanlook.com/. 上面提到的3个模块都属于第三方扩展模块，需要提前下好源码，然后编译时通过  --add-moudle=src_path一起安装. </div></div></div></div><div id="sidebar"><div class="sidebar"><form enctype="application/x-www-form-urlencoded" method="get" action="/search.jsp" name="search"><input type="text" size="24" name="q"></input><input name="s" value="搜索" type="submit"></input></form></div><div class="sidebar"><div id="ad"><script type="text/javascript">
							/*右侧*/
							var cpro_id = "u1896355";
						</script><script type="text/javascript" src="http://cpro.baidustatic.com/cpro/ui/c.js"></script></div></div><div class="sidebar"><h4>相关文章</h4><ul><li><a title="常见分布式负载均衡工具介绍nginx lighttpd haproxy" href="/detail/50637-%E8%B4%9F%E8%BD%BD-%E5%B7%A5%E5%85%B7-nginx">常见分布式负载均衡工具介绍nginx lighttpd haproxy</a></li><li><a title="解析nginx负载均衡" href="/detail/38901-%E8%A7%A3%E6%9E%90-nginx-%E8%B4%9F%E8%BD%BD">解析nginx负载均衡</a></li><li><a title="nginx负载均衡配置" href="/detail/39452-nginx-%E8%B4%9F%E8%BD%BD">nginx负载均衡配置</a></li><li><a title="Nginx负载均衡概览" href="/detail/50995-nginx-%E8%B4%9F%E8%BD%BD">Nginx负载均衡概览</a></li><li><a title="使用Nginx做mssql只读库负载均衡" href="/detail/39938-nginx-mssql-%E8%B4%9F%E8%BD%BD">使用Nginx做mssql只读库负载均衡</a></li><li><a title="Nginx+keepalived做双机热备加tomcat负载均衡" href="/detail/41849-nginx-keepalived-tomcat">Nginx+keepalived做双机热备加tomcat负载均衡</a></li><li><a title="centos下搭建nginx+tomcat实现集群负载与session复制" href="/detail/43471-centos-nginx-tomcat">centos下搭建nginx+tomcat实现集群负载与session复制</a></li><li><a title="Nginx+keepalived实现负载均衡和高可用性 in ubuntu" href="/detail/45062-nginx-keepalived-%E8%B4%9F%E8%BD%BD">Nginx+keepalived实现负载均衡和高可用性 in ubuntu</a></li><li><a title="实现基于nginx的tomcat负载均衡和集群配置" href="/detail/52307-nginx-tomcat-%E8%B4%9F%E8%BD%BD">实现基于nginx的tomcat负载均衡和集群配置</a></li><li><a title="nginx做负载均衡器以及proxy缓存配置" href="/detail/53587-nginx-%E8%B4%9F%E8%BD%BD-%E5%9D%87%E8%A1%A1%E5%99%A8">nginx做负载均衡器以及proxy缓存配置</a></li></ul></div><div class="sidebar"><h4>订阅</h4><div id="sub"><ul><li><a shape="rect" class="rss" title="RSS" href="/feed.jsp">RSS</a></li></ul></div></div><!--
			<div class="sidebar">
					<div id="ad2">

					
			   		</div>	
			</div>
--></div></div><div id="footer"><hr/><div id="site_nav"><ul><li>©2013 Powered by <a shape="rect" href="http://itindex.net/">ITIndex</a></li><li><a shape="rect" href="/blog">博客</a></li><li><a shape="rect" href="/about">关于</a></li></ul></div><div class="copy"><a shape="rect" href="http://itindex.net/">IT瘾</a> 坚持分享优质有趣的原创文章，并保留作者信息和版权声明，任何问题请联系：itarea.cn@gmail.com。
</div></div></div><script data="type=tools&amp;uid=1486471" id="bdshare_js" type="text/javascript"></script><script id="bdshell_js" type="text/javascript"></script><script type="text/javascript">
document.getElementById("bdshell_js").src = "http://bdimg.share.baidu.com/static/js/shell_v2.js?cdnversion=" + Math.ceil(new Date()/3600000);
//document.getElementById("ad").innerHTML='推荐：<a shape="rect" target="_blank" href="http://www.brandstroy.com/files/webpage.html">应用开发托管服务</a>';
</script><!-- Baidu Button END --></body></html>