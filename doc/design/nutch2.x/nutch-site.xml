<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
	<property>
		<name>http.agent.name</name>
		<value>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.7 Safari/537.36 nutch/2.4</value>
		<description>HTTP 'User-Agent' request header. MUST NOT be empty -
			please set this to a single word uniquely related to your organization.
		</description>
	</property>
	<property>
		<name>parser.character.encoding.default</name>
		<value>utf-8</value>
		<description>The character encoding to fall back to when no other information
			is available
		</description>
	</property>
	<property>
		<name>storage.data.store.class</name>
		<value>org.apache.gora.hbase.store.HBaseStore</value>
		<description>The Gora DataStore class for storing and retrieving data.
			Currently the following stores are available:
		</description>
	</property>
	<property>
		<name>db.ignore.external.links</name>
		<value>true</value>
		<description>If true, outlinks leading from a page to external hosts
			will be ignored. This is an effective way to limit the crawl to include
			only initially injected hosts, without creating complex URLFilters.
		</description>
	</property>
	<property>
		<name>fetcher.threads.fetch</name>
		<value>10</value>
		<description>The number of FetcherThreads the fetcher should use.
			This is also determines the maximum number of requests that are
			made at once (each FetcherThread handles one connection). The total
			number of threads running in distributed mode will be the number of
			fetcher threads * number of nodes as fetcher has one map task per node.
		</description>
	</property>
	<property>
		<name>fetcher.threads.per.queue</name>
		<value>2</value>
		<description>This number is the maximum number of threads that
			should be allowed to access a queue at one time. Setting it to
			a value > 1 will cause the Crawl-Delay value from robots.txt to
			be ignored and the value of fetcher.server.min.delay to be used
			as a delay between successive requests to the same server instead
			of fetcher.server.delay.
		</description>
	</property>
	<property>
		<name>fetcher.server.min.delay</name>
		<value>2</value>
		<description>The minimum number of seconds the fetcher will delay between
			successive requests to the same server. This value is applicable ONLY
			if fetcher.threads.per.queue is greater than 1 (i.e. the host blocking
			is turned off).
		</description>
	</property>
	<property>
		<name>plugin.folders</name>
		<value>src/plugin</value>
		<description>Directories where nutch plugins are located. Each
			element may be a relative or absolute path. If absolute, it is used
			as is. If relative, it is searched for on the classpath.
		</description>
	</property>
	<property>
		<name>plugin.includes</name>
		<value>protocol-http|urlfilter-regex|parse-(html|tika)|index-(basic|anchor)|indexer-solr|urlnormalizer-(pass|regex|basic)|scoring-opic</value>
		<description>Regular expression naming plugin directory names to
			include. Any plugin not matching this expression is excluded.
			In any case you need at least include the nutch-extensionpoints plugin. By
			default Nutch includes crawling just HTML and plain text via HTTP,
			and basic indexing and search plugins. In order to use HTTPS please enable
			protocol-httpclient, but be aware of possible intermittent problems with the
			underlying commons-httpclient library.
		</description>
	</property>

</configuration>
